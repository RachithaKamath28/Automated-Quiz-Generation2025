more than 2000 years ago, the greeks were able to convey their architectural ideas graphically, even though the related mathematics was not developed until the re- naissance.today,thesametypeofinformationisgeneratedbyarchitects,mechanical designers,anddraftspeopleusingcomputer-baseddraftingsystems.
overthepast150years,workersinthefieldofstatisticshaveexploredtechniques for generating plots that aid the viewer in understanding the information in a set ofdata.now,wehavecomputerplottingpackagesthatprovideavarietyofplotting techniquesandcolortoolsthatcanhandlemultiplelargedatasets.nevertheless, it is still the humans ability to recognize visual patterns that ultimately allows us to interprettheinformationcontainedinthedata.thefieldofinformationvisualiza- tionisbecomingincreasinglymoreimportantaswehavetodealwithunderstanding complexphenomenafromproblemsinbioinformaticstodetectingsecuritythreats.
medicalimagingposesinterestingandimportantdata-analysisproblems.mod- ernimagingtechnologiessuchascomputedtomography(ct),magneticresonance imaging (mri), ultrasound, and positron-emission tomography (pet)generate three-dimensionaldatathatmustbesubjectedtoalgorithmicmanipulationtopro- videusefulinformation.colorplate20showsanimageofapersonsheadinwhich the skin is displayed as transparent and the internal structures are displayed as opaque.
1.1.2 design professionssuchasengineeringandarchitectureareconcernedwithdesign.starting withasetofspecifications,engineersandarchitectsseekacost-effectiveandesthetic solutionthatsatisfiesthespecifications.designisaniterativeprocess.rarelyinthe realworldisaproblemspecifiedsuchthatthereisauniqueoptimalsolution.design problemsareeitheroverdetermined,suchthattheypossessnosolutionthatsatisfies all the criteria, much less an optimal solution, or underdetermined, such that they have multiple solutions that satisfy the design criteria.
she generates a possible design, tests it, and then uses the results as the basisforexploringothersolutions.
in all these applica- tions, the graphics are used in a number of distinct ways.
1.1.3 simulation and animation once graphics systems evolved to be capable of generating sophisticated images in real time, engineers and researchers began to use them as simulators.
one of the most important uses has been in the training of pilots.
she can then act as part of a computer-generated scene, limited only by the image-generation ability of the computer.
for example, a surgical intern might be trained to do an operation in this way, or an astronaut might be trained to work in a weightless environment.
to a large degree, games drive the development of graphics hardware.
on the commercial side, the revenue from video games has surpassed the revenue for commercial films.
1.2 agraphicssystem 5 1.1.4 user interfaces our interaction with computers has become dominated by a visual paradigm that includes windows, icons, menus, and a pointing device, such as a mouse.
from a users perspective, windowing systems such as the x window system, microsoft windows, and the macintosh os x differ only in details.
1.2 a graphics system a computer graphics system is a computer system; as such, it must have all the componentsofageneral-purposecomputersystem.letusstartwiththehigh-level viewofagraphicssystem,asshownintheblockdiagraminfigure1.1.therearefive majorelementsinoursystem: 1. inputdevices 2. processor 3. memory 4. framebuffer 5. outputdevices thismodelisgeneralenoughtoincludeworkstationsandpersonalcomputers,inter- active game systems, and sophisticated image-generation systems.
collectively, the pixels are stored in a part of memory called the frame buffer.theframebuffercanbeviewedasthecoreelementofagraphicssystem.its resolutionthe number of pixels in the frame bufferdetermines the detail that youcanseeintheimage.thedepth,orprecision,oftheframebuffer,definedasthe numberofbitsthatareusedforeachpixel,determinespropertiessuchashowmany colorscanberepresentedonagivensystem.forexample,a1-bit-deepframebuffer allows only two colors, whereas an 8-bit-deep frame buffer allows 28 (256) colors.
infull-colorsystems,thereare24(ormore)bitsperpixel.suchsystemscandisplay sufficientcolorstorepresentmostimagesrealistically.theyarealsocalledtrue-color systems, or rgb-color systems, because individual groups of bits in each pixel are 1.2 agraphicssystem 7 assigned to each of the three primary colorsred, green, and blueused in most displays.
theframebufferusuallyisimplementedwithspecialtypesofmemorychipsthat enablefastredisplayofthecontentsoftheframebuffer.insoftware-basedsystems, such as those used for high-resolution rendering or for generating complex visual effects that cannot be produced in real time, the frame buffer is part of system memory.
inasimplesystem,theremaybeonlyoneprocessor,thecentralprocessingunit (cpu)ofthesystem,whichmustdoboththenormalprocessingandthegraphical processing.themaingraphicalfunctionoftheprocessoristotakespecificationsof graphical primitives (such as lines, circles, and polygons) generated by application programs and to assign values to the pixels in the frame buffer that best represent theseentities.forexample,atriangleisspecifiedbyitsthreevertices,buttodisplay its outline by the three line segments connecting the vertices, the graphics system mustgenerateasetofpixelsthatappearaslinesegmentstotheviewer.theconver- sionofgeometricentitiestopixelcolorsandlocationsintheframebufferisknown asrasterization,orscanconversion.inearlygraphicssystems,theframebufferwas partofthestandardmemorythatcouldbedirectlyaddressedbythecpu.today,vir- tuallyallgraphicssystemsarecharacterizedbyspecial-purposegraphicsprocessing units(gpus),custom-tailoredtocarryoutspecificgraphicsfunctions.thegpucan beeitheronthemotherboardofthesystemoronagraphicscard.theframebuffer isaccessedthroughthegraphicsprocessingunitandmaybeincludedinthegpu.
1.2.2 output devices for many years, the dominant type of display (or monitor) has been the cathode- ray tube (crt).
although various flat-panel technologies are now more popular, the basic functioning of the crt has much in common with these newer displays.
a simplified picture of a crt is shown in figure 1.3. when electrons strike the phosphorcoatingonthetube,lightisemitted.thedirectionofthebeamiscontrolled bytwopairsofdeflectionplates.theoutputofthecomputerisconverted,bydigital- to-analogconverters, tovoltagesacrossthex andy deflectionplates.lightappears 8 chapter1 graphicssystemsandmodels y deflect electron gun x deflect phosphor focus figure1.3 thecathode-raytube(crt).
such a device is known as the random-scan, calligraphic, or vector crt, because the beam can be moved directly from any positiontoanyotherposition.iftheintensityofthebeamisturnedoff,thebeamcan bemovedtoanewpositionwithoutchanginganyvisibledisplay.thisconfiguration wasthebasisofearlygraphicssystemsthatpredatedthepresentrastertechnology.
atypicalcrtwillemitlightforonlyashorttimeusually,afewmilliseconds after the phosphor is excited by the electron beam.
for a human to see a steady, flicker-free image on most crt displays, the same path must be retraced, or re- freshed, by the beam at a sufficiently high rate, the refreshrate.
in a raster system, the graphics system takes pixels from the frame buffer and displaysthemaspointsonthesurfaceofthedisplayinoneoftwofundamentalways.
figure 1.5 shows a generic flat- panelmonitor.thetwooutsideplatescontainparallelgridsofwiresthatareoriented perpendiculartoeachother.bysendingelectricalsignalstotheproperwireineach grid,theelectricalfieldatalocation,determinedbytheintersectionoftwowires,can be made strong enough to control the corresponding element in the middle plate.
1.2.3 input devices mostgraphicssystemsprovideakeyboardandatleastoneotherinputdevice.the most common input devices are the mouse, the joystick, and the data tablet.
1.3 images: physical and synthetic the traditional pedagogical approach to teaching computer graphics has been fo- cused on how to construct raster images of simple two-dimensional geometric en- tities (for example, points, line segments, and polygons) in the frame buffer.
in this chapter, we argue that the pre- ferredmethodtoformcomputer-generatedimagesissimilartotraditionalimaging methods, such as cameras and the human visual system.
1.3.1 objects and viewers weliveinaworldofthree-dimensionalobjects.thedevelopmentofmanybranches of mathematics, including geometry and trigonometry, was in response to the de- siretosystematizeconceptuallysimpleideas,suchasthemeasurementofthesizeof objectsandthedistancebetweenobjects.oftenweseektorepresentourunderstand- ing of such spatial relationships with pictures or images, such as maps, paintings, and photographs.
inthehumanvisualsystem,theimageisformedonthebackoftheeye.inacamera, the image is formed in the film plane.
figure1.7showsacamerasystemviewingabuilding.herewecanobservethat both the object and the viewer exist in a three-dimensional world.
however, the image that they definewhat we find on the film planeis two dimensional.
the processbywhichthespecificationoftheobjectiscombinedwiththespecificationof the viewer to produce a two-dimensional image is the essence of image formation, andwewillstudyitindetail.
light from the source strikes various surfaces of the object, and a portion of the reflected light enters the camera through the lens.
the details of the interaction between light and the surfaces of the object determine how much light enters the camera.
a given light source has a color determined by the energy that it emits at various wavelengths.
wavelengths in the middle of the range, around 520 nm, are seen as green;thosenear450nmareseenasblue;andthosenear650nmareseenasred.just aswitharainbow,lightatwavelengthsbetweenredandgreenweseeasyellow,and wavelengthsshorterthanbluegeneratevioletlight.
these rays can interact with the objects surfaces in a vari- etyofways.forexample,ifthesurfaceisamirror,areflectedraymightdepending ontheorientationofthesurfaceenterthelensofthecameraandcontributetothe image.othersurfacesscatterlightinalldirections.ifthesurfaceistransparent,the light ray from the source can pass through it and may interact with other objects, enterthecamera,ortraveltoinfinitywithoutstrikinganothersurface.4figure1.11 showssomeofthepossibilities.
1.4 imaging systems wenowintroducetwophysicalimagingsystems:thepinholecameraandthehuman visualsystem.thepinholecameraisasimpleexampleofanimagingsystemthatwill enableustounderstandthefunctioningofcamerasandofotheropticalimagers.we emulateittobuildamodelofimageformation.thehumanvisualsystemisextremely complexbutstillobeysthephysicalprinciplesofotheropticalimagingsystems.we introduce it not only as an example of an imaging system but also because under- standing its properties will help us to exploit the capabilities of computer-graphics systems.
calculatewheretheimageofthepoint (x,y,z)isonthefilmplane zd.using the fact that the two triangles shown in figure 1.13 are similar, we find that the y coordinateoftheimageisaty ,where p y y  .
p zd the point (x ,y ,d) is called the projection of the point (x,y,z).
the larger the aperture of the lens, the more light the lens can collect.
lens iris rods and cones 1.4.2 the human visual system ourextremelycomplexvisualsystemhasallthecomponentsofaphysicalimaging optic nerve system, such as a camera or a microscope.
the major components of the visual figure 1.15 the human systemareshowninfigure1.15.lightenterstheeyethroughthelensandcornea, visualsystem.
the lens forms an image on a two-dimensional structure called the retina at the back of the eye.
the rods and cones (so named because of their appearance when magnified) are light sensors and are located on theretina.theyareexcitedbyelectromagneticenergyintherangeof350to780nm.
thesensorsinthehumaneyedonotreactuniformlytolightenergyatdifferent wavelengths.therearethreetypesofconesandasingletypeofrod.whereasintensity is a physical measure of light energy, brightness is a measure of how intense we 1.5 thesynthetic-cameramodel 19 perceivethelightemittedfromanobjecttobe.thehumanvisualsystemdoesnot have the same response to a monochromatic (single-frequency) red light as to a monochromatic green light.
if these two lights were to emit the same energy, they would appear to us to have different brightness, because of the unequal response of the cones to red and green light.
brightnessisanoverallmeasureofhowwereacttotheintensityoflight.human color-vision capabilities are due to the different sensitivities of the three types of cones.themajorconsequenceofhavingthreetypesofconesisthatinsteadofhaving toworkwithallvisiblewavelengthsindividually,wecanusethreestandardprimaries toapproximateanycolorthatwecanperceive.consequently,mostimage-production systems,includingfilmandvideo,workwithjustthreebasic,orprimary,colors.we discusscolorindepthinchapter2.
however, the human visual system has a back end much more complex than that of a camera or telescope.
the optic nerve is connected to the rods and cones in an extremely complex arrangement that has manyofthecharacteristicsofasophisticatedsignalprocessor.thefinalprocessing is done in a part of the brain called the visual cortex, where high-level functions, suchasobjectrecognition,arecarriedout.wewillomitanydiscussionofhigh-level processing;instead,wecanthinksimplyintermsofanimagethatisconveyedfrom therodsandconestothebrain.
1.5 the synthetic-camera model our models of optical imaging systems lead directly to the conceptual foundation formodernthree-dimensionalcomputergraphics.welookatcreatingacomputer- generatedimageasbeingsimilartoforminganimageusinganopticalsystem.this paradigmhasbecomeknownasthesynthetic-cameramodel.considertheimaging system shown in figure 1.16. again we see objects and a viewer.
in this case, the viewer is a bellows camera.6 the image is formed on the film plane at the back of thecamera.sothatwecanemulatethisprocesstocreateartificialimages,weneedto identifyafewbasicprinciples.
first, the specification of the objects is independent of the specification of the viewer.hence,weshouldexpectthat,withinagraphicslibrary,therewillbeseparate functionsforspecifyingtheobjectsandtheviewer.
6. in a bellows camera, the front of the camera, where the lens is located, and the back of the camera,thefilmplane,areconnectedbyflexiblesides.thus,wecanmovethebackofthecamera independentlyofthefrontofthecamera,introducingadditionalflexibilityintheimage-formation process.weusethisflexibilityinchapter5.
note that the image of the object is flipped relative to the object.
whereas with a real camera, we would simply flip the film to regain the original orientation of the object,withoursyntheticcamerawecanavoidtheflippingbyasimpletrick.wedraw anotherplaneinfrontofthelens(figure1.17(b)),andworkinthreedimensions,as showninfigure1.18.wefindtheimageofapointontheobjectonthevirtualimage planebydrawingaline,calledaprojector,fromthepointtothecenterofthelens,or thecenterofprojection(cop).notethatallprojectorsareraysemanatingfromthe centerofprojection.inoursyntheticcamera, thevirtualimageplanethatwehave movedinfrontofthelensiscalledtheprojectionplane.theimageofthepointis located where the projector passes through the projection plane.
given the location of the center of projection, the location 1.6 theprogrammersinterface 21 figure1.18 imagingwiththesyntheticcamera.
1.6 the programmers interface there are numerous ways that a user can interact with a graphics system.
the interface between an application program and a graphics system can be specified through a set of functions that resides in a graphics library.
from the perspective of the writer of an 1.6 theprogrammersinterface 23 applicationprogram,thefunctionsavailablethroughtheapishouldmatchthecon- ceptualmodelthattheuserwishestoemploytospecifyimages.7 1.6.1 the pen-plotter model historically,mostearlygraphicssystemsweretwo-dimensionalsystems.theconcep- tualmodelthattheyusedisnowreferredtoasthepen-plottermodel,referencingthe outputdevicethatwasavailableonthesesystems.apenplotter(figure1.22)pro- figure1.22 penplotter.
wecandescribesuchagraphicssystemwiththefollowingdrawingfunctions: moveto(x,y) lineto(x,y) executionofthemovetofunctionmovesthepentothelocation(x,y)onthepaper withoutleavingamark.thelinetofunctionmovesthepento(x,y)anddrawsa line from the old to the new location of the pen.
24 chapter1 graphicssystemsandmodels lineto(1, 0); moveto(1, 1); lineto(1,5,1.866); we would have the image of a cube formed by an oblique projection, as shown in figure1.23(b).
square, and (b) a projection we are much more interested, however, in the three-dimensional world.
pen-plottermodeldoesnotextendwelltothree-dimensionalgraphicssystems.for example, if we wish to use the pen-plotter model to produce the image of a three- dimensionalobjectonourtwo-dimensionalpad,eitherbyhandorbycomputer,then wehavetofigureoutwhereonthepagetoplacetwo-dimensionalpointscorrespond- ing to points on our three-dimensional object.
we develop the mathematics of projection in chapter 5; understanding projection is crucial to understanding three-dimensional graphics.
for simple geometric objects b such as line segments, rectangles, and polygonsthere is a simple relationship be- tween a list of vertices, or positions in space, and the object.
if we change the type parameter, gl polygon, we can use the same vertices to define a different geometric primitive.
for example, the type gllinestrip uses the vertices to define two connected line segments, whereas the type glpoints uses the same vertices to define three w points.
2. orientation once we have positioned the camera, we can place a camera coordinate system with its origin at the center of projection.
one way to develop the specifications for the camera location and orientation uses a series of coordinate- systemtransformations.thesetransformationsconvertobjectpositionsrepresented inacoordinatesystemthatspecifiesobjectverticestoobjectpositionsinacoordinate systemcenteredatthecop.thisapproachisuseful,bothforimplementingandfor gettingthefullsetofviewsthataflexiblecameracanprovide.weusethisapproach extensively,startinginchapter5.
part of the problem lies with the synthetic-camera model.
classical viewing techniques, such as the ones used in architecture, stress the relationship betweentheobjectandtheviewer,ratherthantheindependence thatthesynthetic- cameramodelemphasizes.thus,theclassicaltwo-pointperspectiveofacubeshown infigure1.26isatwo-point perspectivebecauseofaparticularrelationshipbetween theviewerandtheplanesofthecube(seeexercise1.7).althoughtheopenglapi allowsustosettransformationswithcompletefreedom,italsoprovideshelpfulextra functions.forexample,considerthefollowingfunctioncalls: glulookat(copx, copy, copz, atx, aty, atz, upx, upy, upz); glperspective(fieldofview, aspectratio, near, far); thefirstfunctioncallpointsthecamerafromacenterofprojectiontowardadesired point(theat point),withaspecifiedupdirectionforthecamera.thesecondselects a lens for a perspective view (the field of view) and how much of the world that thecamerashouldimage(theaspectratioandthenear andfar distances).however, noneoftheapisbuiltonthesynthetic-cameramodelprovidefunctionsfordirectly specifyingadesiredrelationshipbetweenthecameraandanobject.
apisprovideasetoffunctionstospecifytheseparametersforeachsource.material properties are characteristics, or attributes, of the objects, and such properties are specified through a series of function calls at the time that each object is defined.
we present these images as an increasingly more complex series of renderings of the same objects.
the sequence not only loosely follows the order in whichwepresentrelatedtopicsbutalsoreflectshowgraphicssystemshavedeveloped overthepast30years.
colorplate1showsanimageofanartistscreationofasun-likeobject.color plate2showstheobjectrenderedusingonlylinesegments.althoughtheobjectcon- sistsofmanyparts,andalthoughtheprogrammermayhaveusedsophisticateddata structures to model each part and the relationships among the parts, the rendered objectshowsonlytheoutlinesoftheparts.thistypeofimageisknownasawire- frameimagebecausewecanseeonlytheedgesofsurfaces:suchanimagewouldbe producediftheobjectswereconstructedwithstiffwiresthatformedaframewithno solid material between the edges.
most raster systems can fill the interior of polygons with a solid color in approxi- matelythesametimethattheycanrenderawireframeimage.althoughtheobjects arethreedimensional,eachsurfaceisdisplayedinasinglecolor,andtheimagefailsto showthethree-dimensionalshapesoftheobjects.earlyrastersystemscouldproduce imagesofthisform.
color plate 4 illustrates smooth shading of the polygons that approximate the object; it shows that the object is three dimensional and gives the appearance of a smoothsurface.wedevelopshadingmodelsthataresupportedbyopenglinchap- ter6.theseshadingmodelsarealsosupportedinthehardwareofmostrecentwork- stations; generating the shaded image on one of these systems takes approximately thesameamountoftimeasdoesgeneratingawireframeimage.
in color plates 6 and 7, we add surface texture to our object; texture is one of the effects that we discuss in chapter 8. all recent graphics processors support 28 chapter1 graphicssystemsandmodels texturemappinginhardware,sorenderingofatexture-mappedimagerequireslittle additionaltime.incolorplate6,weuseatechniquecalledbumpmapping thatgives theappearanceofaroughsurfaceeventhoughwerenderthesameflatpolygonsasin theotherexamples.colorplate7showsanenvironmentmapappliedtothesurfaceof theobject,whichgivesthesurfacetheappearanceofamirror.thesetechniqueswill bediscussedindetailinchapters8and9.
in addition, just as the images show incremental changes in the renderings, the programsareincrementallydifferentfromoneanother.
one of the other advantages of this approach is that it allows us to develop modelers that, althoughtheyusethesamerenderer,aretailoredtoparticularapplications.likewise, differentrendererscantakeasinputthesameinterfacefile.itisevenpossible,atleast inprinciple,todispensewiththemodelercompletelyandtouseastandardtexteditor togenerateaninterfacefile.foranybutthesimplestscenes,however,userscannot edit lists of information for a renderer.
1.7 graphics architectures ononesideoftheapiistheapplicationprogram.ontheothersideissomecom- bination of hardware and software that implements the functionality of the api.
earlygraphicssystemsusedgeneral-purposecomputerswiththestandardvon neumannarchitecture.suchcomputersarecharacterizedbyasingleprocessingunit thatprocessesasingleinstructionatatime.asimplemodeloftheseearlygraphics systems is shown in figure 1.28. the display in these systems was based on a calli- graphiccrtdisplaythatincludedthenecessarycircuitrytogeneratealinesegment connectingtwopoints.thejobofthehostcomputerwastoruntheapplicationpro- gramandtocomputetheendpointsofthelinesegmentsintheimage(inunitsofthe display).thisinformationhadtobesenttothedisplayataratehighenoughtoavoid flickeronthedisplay.intheearlydaysofcomputergraphics,computersweresoslow thatrefreshingevensimpleimages,containingafewhundredlinesegments,would burdenanexpensivecomputer.
1.7.1 display processors theearliestattemptstobuildspecial-purposegraphicssystemswereconcernedpri- marilywithrelievingthegeneral-purposecomputerfromthetaskofrefreshingthe displaycontinuously.thesedisplayprocessorshadconventionalarchitectures(fig- ure1.29)butincludedinstructionstodisplayprimitivesonthecrt.themainad- vantageofthedisplayprocessorwasthattheinstructionstogeneratetheimagecould be assembled once in the host and sent to the display processor, where they were storedinthedisplayprocessorsownmemoryasadisplaylist, ordisplayfile.the displayprocessorwouldthenexecuterepetitivelytheprograminthedisplaylist, at aratesufficienttoavoidflicker,independentlyofthehost,thusfreeingthehostfor othertasks.thisarchitecturehasbecomecloselyassociatedwiththeclientserverar- chitecturesthatwewilldiscussinchapter3.
pipeliningissimilartoanassemblylineinacarplant.asthechassispassesdown the line, a series of operations is performed on it, each using specialized tools and workers,untilattheend,theassemblyprocessiscomplete.atanyonetime,multiple carsareunderconstructionandthereisasignificantdelayorlatencybetweenwhen achassisstartsdowntheassemblylineandthefinishedvehicleiscomplete.however, thenumberofcarsproducedinagiventime,thethroughput,ismuchhigherthanif asingleteambuilteachcar.
the concept of pipelining is illustrated in figure 1.30 for a simple arithmetic calculation.inourpipeline,thereisanadderandamultiplier.ifweusethisconfigu- rationtocomputea(bc),thenthecalculationtakesonemultiplicationandone additionthe same amount of work required if we use a single processor to carry outbothoperations.however,supposethatwehavetocarryoutthesamecomputa- 1.7 graphicsarchitectures 31 a b  c  figure1.30 arithmeticpipeline.
we can construct pipelines for more complex arithmetic calculations that will affordevengreaterincreasesinthroughput.ofcourse,thereisnopointinbuilding a pipeline unless we will do the same operation on many data sets.
1.7.3 the graphics pipeline westartwithasetofobjects.eachobjectcomprisesasetofgraphicalprimitives.each primitivecomprisesasetofvertices.wecanthinkofthecollectionofprimitivetypes andverticesasdefiningthegeometryofthescene.inacomplexscene,theremaybe thousandseven millionsof vertices that define the objects.
the two major functions of this block are to carry out coordinate transformations and to computeacolorforeachvertex.
in general, we want to keep three-dimensional information as long as possible, as objects pass through thepipeline.consequently,theprojectiontransformationissomewhatmoregeneral than the projections in section 1.5. in addition to retaining three-dimensional in- formation,thereisavarietyofprojectionsthatwecanimplement.wewillseethese projectionsinchapter5.
the assignment of vertex colors can be as simple as the program specifying a colororascomplexasthecomputationofacolorfromaphysicallyrealisticlighting model that incorporates the surface properties of the object and the characteristic lightsourcesinthescene.wewilldiscusslightingmodelsinchapter6.
1.7.5 clipping and primitive assembly the second fundamental block in the implementation of the standard graphics pipelineisforclippingandprimitiveassembly.wemustdoclippingbecauseofthe limitationthatnoimagingsystemcanseethewholeworldatonce.thehumanretina hasalimitedsizecorrespondingtoanapproximately90-degreefieldofview.cameras havefilmoflimitedsize,andwecanadjusttheirfieldsofviewbyselectingdifferent lenses.
1.7.6 rasterization the primitives that emerge from the clipper are still represented in terms of their vertices and must be further processed to generate pixels in the frame buffer.
for example, if three vertices specify a triangle filled with a solid color, the rasterizer mustdeterminewhichpixelsintheframebufferareinsidethepolygon.wediscuss this rasterization (or scan-conversion) process in chapter 8 for line segments and polygons.
the output of the rasterizer is a set of fragments for each primitive.
a fragment can be thought of as a potential pixel that carries with it information, including its color and location, that is used to update the corresponding pixel in theframebuffer.fragmentscanalsocarryalongdepthinformationthatallowslater stages to determine if a particular fragment lies behind other previously rasterized fragmentsforagivenpixel.
the color of a fragment may be altered by texture mapping or bump mapping as shown in color plates 6 and 7. the color of the pixel that correspondstoafragmentcanalsobereadfromtheframebufferandblendedwith the fragments color to create translucent effects.
1.8 programmable pipelines graphics architectures have gone through multiple cycles in which the importance of special-purpose hardware relative to standard cpus has gone back and forth.
formanyyears,thesepipelinearchitectureshadafixedfunctionality.although the application program could set many parameters, the basic operations available within the pipeline were fixed.
recently,therehasbeenamajoradvanceinpipelinearchitectures.boththever- tex processor and the fragment processor are now programable by the application program.oneofthemostexcitingaspectsofthisadvanceisthatmanyofthetech- niquesthatformerlycouldnotbedoneinrealtimebecausetheywerenotpartofthe fixed-functionpipelinecannowbedoneinrealtime.
the geometry engine developed by silicon graphics, inc. (sgi) wasavlsiimplementationformanyoftheseoperationsinaspecial-purposechip thatbecamethebasisforaseriesoffastgraphicsworkstations.later,floating-point accelerator chips put 4  4 matrix-transformation units on the chip, reducing a matrixmultiplicationtoasingleinstruction.today,graphicsworkstationsandcom- moditygraphicscardsusegraphicsprocessingunits(gpus)thatperformmostofthe graphicsoperationsatthechiplevel.pipelinearchitecturesarethedominanttypeof high-performancesystem.
the overall performance of a system is characterized by how fast we can move geometric entities through the pipeline and by how many pixels per second wecanalterintheframebuffer.consequently,thefastestgraphicsworkstationsare characterizedbyoneormoregeometricpipelinesatthefrontendsandparallelbit processors at the back ends.